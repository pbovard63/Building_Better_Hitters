{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to house code used to scrape from baseball reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Project 2 Savant Code notebook for further detail, had issues merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the needed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import stats\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from IPython.core.display import display, HTML    # make sure Jupyter knows to display it as HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function to use the URL's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Player_URL_Generator(player_list):\n",
    "    '''\n",
    "    Takes a list of player names, with each name being an entry of first name and last name.\n",
    "    Returns a URL on baseball reference to each player's original page.\n",
    "    '''\n",
    "    separated_names = [player.split(\" \") for player in player_list]\n",
    "    url_list = []\n",
    "    for i, player in enumerate(separated_names):\n",
    "        #Stripping punctuation from names:\n",
    "        new_name = [name.replace(\".\",\"\") for name in player]\n",
    "        new_name = [name.replace(\"'\",\"\") for name in new_name]\n",
    "        #print(len(new_name))\n",
    "        #In other words, if a player has 3 names not two:\n",
    "        if len(new_name) == 3:\n",
    "            comb_name = [new_name[0], new_name[1]+new_name[2]]\n",
    "            #print(comb_name)\n",
    "            if len(comb_name[1]) <= 5:\n",
    "                url = 'https://www.baseball-reference.com/players/{}/{}{}01.shtml'.format(comb_name[1][0].lower(), comb_name[1].lower(), comb_name[0][0:2].lower())\n",
    "            else:\n",
    "                url = 'https://www.baseball-reference.com/players/{}/{}{}01.shtml'.format(comb_name[1][0].lower(), comb_name[1][0:5].lower(), comb_name[0][0:2].lower())\n",
    "        else:    \n",
    "            if len(new_name[1]) <= 5:\n",
    "                url = 'https://www.baseball-reference.com/players/{}/{}{}01.shtml'.format(new_name[1][0].lower(), new_name[1].lower(), new_name[0][0:2].lower())\n",
    "            else:\n",
    "                url = 'https://www.baseball-reference.com/players/{}/{}{}01.shtml'.format(new_name[1][0].lower(), new_name[1][0:5].lower(), new_name[0][0:2].lower())\n",
    "        url_list.append(url)\n",
    "    return url_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing URL Generator w/ edge cases (apostrophes, periods in name, spaces in name, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.baseball-reference.com/players/o/oneilty01.shtml',\n",
       " 'https://www.baseball-reference.com/players/d/darnach01.shtml',\n",
       " 'https://www.baseball-reference.com/players/c/croncj01.shtml',\n",
       " 'https://www.baseball-reference.com/players/l/lasteto01.shtml',\n",
       " 'https://www.baseball-reference.com/players/d/deazaal01.shtml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Player_URL_Generator([\"Tyler O'Neill\", \"Chase d'Arnaud\", \"C.J. Cron\", 'Tommy La Stella','Alejandro De Aza'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Player URL Function, generating a BS4 object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Player_Soup_Generator(player_list):\n",
    "    '''\n",
    "    Takes in a list of players and returns Beautiful Soup objects.\n",
    "    '''\n",
    "    url_list = Player_URL_Generator(player_list)\n",
    "    response_list = [requests.get(url) for url in url_list]\n",
    "    soup_list = []\n",
    "    for response in response_list:\n",
    "        page = response.text\n",
    "        soup_object = BeautifulSoup(page,'lxml')\n",
    "        name = player.title.text.split(\"Stats\")[0]\n",
    "        #if player_list[i].strip() != name.strip():\n",
    "            #Add in code for updating URL in this case\n",
    "        soup_list.append(BeautifulSoup(page,'lxml'))\n",
    "    return soup_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull the years the player played from baseball reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pull_Player_Seasons(player_soup):\n",
    "    '''\n",
    "    Takes in a player's soup object.\n",
    "    Returns a list of the season the player played in.\n",
    "    '''\n",
    "    seasons = player_soup.find_all('tr', attrs={'id':re.compile('batting_standard.')})\n",
    "    #seasons = player_soup.find_all('tr', attrs={'data-stat':re.compile('')})\n",
    "    seasons_played = []\n",
    "    for season in seasons:\n",
    "        season_item = [str(item.get_text()) for item in season.find_all('th')]\n",
    "        seasons_played.append(season_item)\n",
    "    return seasons_played"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull the year by year stats from BBREF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pull_Player_Stats(player_soup):\n",
    "    '''\n",
    "    Takes in a player's soup object.\n",
    "    Returns a list of stat lines by season.\n",
    "    '''\n",
    "    stat_line = player_soup.find_all('tr', attrs={'id':re.compile('batting_standard.')})\n",
    "    career_stats = []\n",
    "    for season in stat_line:\n",
    "        season_stat_line = [item.get_text() for item in season.find_all('td')]\n",
    "        career_stats.append(season_stat_line)\n",
    "    for i,year in enumerate(career_stats):\n",
    "        career_stats[i].insert(0,Pull_Player_Seasons(player_soup)[i][0])\n",
    "    return career_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the years and stats, build a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Player_Dataframe_Builder(player_soup_list):\n",
    "    '''\n",
    "    Takes in a list of BeautifulSoup Objects, returns a data frame of their Baseball-Reference stats.\n",
    "    '''\n",
    "    i=0\n",
    "    \n",
    "    for player in player_soup_list:\n",
    "        header = player.find_all('th', attrs={'class': 'poptip'})\n",
    "        columns = [col.get_text() for col in header]\n",
    "        current_player_df = pd.DataFrame(Pull_Player_Stats(player), columns=columns)\n",
    "        if i ==0:\n",
    "            compiled_player_df = pd.DataFrame(columns=columns)\n",
    "            compiled_player_df['Name'] = ''\n",
    "            i += 1\n",
    "        #Adding Player Name as a column:\n",
    "        name = player.title.text.split(\"Stats\")[0]\n",
    "        current_player_df['Name'] = name\n",
    "            \n",
    "        compiled_player_df = pd.concat([compiled_player_df, current_player_df], ignore_index=True)\n",
    "    num_cols = ['Age', 'G', 'PA', 'AB', 'R','H','2B','3B','HR','RBI','SB','CS','BB','SO','BA','OBP','SLG','OPS','OPS+','TB','GDP','HBP','SH','SF','IBB']\n",
    "    compiled_player_df[num_cols] = compiled_player_df[num_cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    return compiled_player_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Case, using the final_player_list from the BasebalL Savant Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_player_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f6a835dc6daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_soup_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlayer_Soup_Generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_player_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'final_player_list' is not defined"
     ]
    }
   ],
   "source": [
    "my_soup_list = Player_Soup_Generator(final_player_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for players whose URL and names don't match using the normal method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, player in enumerate(my_soup_list):\n",
    "    name = player.title.text.split(\"Stats\")[0]\n",
    "    if final_player_list[i].strip() != name.strip():\n",
    "        print('WRONG!')\n",
    "        print(name, final_player_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_player_df = Player_Dataframe_Builder(my_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_player_df.Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_player_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ['Eloy Jimenez','Jose Abreu','Mike Trout','Adam Eaton','Frank Thomas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = Player_URL_Generator(my_list)\n",
    "response_list = [requests.get(url) for url in url_list]\n",
    "soup_list = []\n",
    "for response in response_list:\n",
    "    page = response.text\n",
    "    soup_list.append(BeautifulSoup(page,'lxml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, player in enumerate(soup_list):\n",
    "    name = player.title.text.split(\"Stats\")[0]\n",
    "    print(name)\n",
    "    print(my_list[i])\n",
    "    if str(name) != str(my_list[i]):\n",
    "        print('WRONG!')\n",
    "    else:\n",
    "        print('MATC!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseball reference: had too much trouble using Savant List to pull data based on URL differences from typical function (too many edge/special cases).  \n",
    "**Decision: use wRC+ data from FanGraphs.  FanGraphs has easier access to wRC+, the target stat I want to use with the Savant Data features.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
